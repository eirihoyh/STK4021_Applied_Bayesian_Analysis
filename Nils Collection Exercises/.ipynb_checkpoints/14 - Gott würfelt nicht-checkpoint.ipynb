{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gott w√ºrfelt nicht\n",
    "\n",
    "_but I do so, on demand. I throw a certain moderately strange-looking die 30 times and have counts (2, 5, 3, 7, 5, 8) of outcomes 1, 2, 3, 4, 5, 6._\n",
    "\n",
    "## (a) \n",
    "\n",
    "_Use either of the priors_\n",
    "* 'flat', Dir(1,1,1,1,1,1)\n",
    "* 'symmetric but more confident', Dir(3,3,3,3,3,3)\n",
    "* 'unwilling to guess', Dir(0.1, 0.1, 0.1, 0.1, 0.1, 0.1)\n",
    "\n",
    "_for  the probabilities (p1, . . . , p6) to assess the posterior distribution of each of the following quantities:_\n",
    "\n",
    "* $\\rho = p_6/p_1$ \n",
    "* $\\alpha = \\frac16 \\sum_{j=1}^6 (p_j - \\frac16 )^2$\n",
    "* $\\beta = \\frac16 \\sum_{j=1}^6 |p_j - \\frac16 |$\n",
    "* $\\gamma = \\frac{(p_4p_5p_6)^{\\frac13}}{(p_1p_2p_3)^{\\frac13}}$\n",
    "\n",
    "So, our prior is a Dirichlet, but for the model/likelihood I will use the Multinomial distirbution, which is an \"extensions\" of the binomial. Also note that the Dirichlet is a type of \"extension\" of the beta distribution. Thus, this will almost be the same as a Beta & Binomial problem (Beta prior, Binomial likelihood):\n",
    "\n",
    "Prior:\n",
    "\n",
    "$$\\theta_1, ..., \\theta_6 \\sim Dir(a_1, ..., a_6)$$\n",
    "\n",
    "Likelihood:\n",
    "\n",
    "$$(y_1, ..., y_6)|(\\theta_1, ..., \\theta_6) \\sim Multinomial(n, \\theta_1, ..., \\theta_6)$$\n",
    "\n",
    "Posterior: \n",
    "\n",
    "$$(\\theta_1, ..., \\theta_6)|(y_1, ..., y_6) \\sim Dir(a_1+y_1, ..., a_6+y_6)$$\n",
    "\n",
    "\n",
    "Now that we have established the posterior model, we can solve the problem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "import numpy as np\n",
    "y_vals = np.array([2,5,3,7,5,8])\n",
    "flat_prior = np.array([1,1,1,1,1,1])\n",
    "more_conf_prior = np.array([3,3,3,3,3,3])\n",
    "no_guessing_prior = np.array([0.1,0.1,0.1,0.1,0.1,0.1])\n",
    "\n",
    "first_post = stats.dirichlet.rvs(flat_prior+y_vals, size=10**5)\n",
    "second_post = stats.dirichlet.rvs(more_conf_prior+y_vals, size=10**5)\n",
    "third_post = stats.dirichlet.rvs(no_guessing_prior+y_vals, size=10**5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our different posterior distributions with each of their different prior distributions, we can go on to asses other types of posterior distributions.\n",
    "\n",
    "#### Assess different posterior distributions, with mean, std and credibility interval\n",
    "\n",
    "#### $\\rho = \\frac{p_6}{p_1}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flat prior for p6/p1 posterior distribution:\n",
      "Mean: 4.505, std: 4.591, cred_interval: [ 1.12230793  3.25077806 11.82415953]\n",
      "\n",
      "More confident prior for p6/p1 posterior distribution:\n",
      "Mean: 2.748, std: 1.848, cred_interval: [0.95505602 2.28397805 6.04021986]\n",
      "\n",
      "The no guessing prior for p6/p1 posterior distribution:\n",
      "Mean: 7.338, std: 13.621, cred_interval: [ 1.29693539  4.36749928 21.38520482]\n"
     ]
    }
   ],
   "source": [
    "rho_first_post = first_post[:,-1]/first_post[:,0]\n",
    "mean_rho1 = np.mean(rho_first_post)\n",
    "std_rho1 = np.std(rho_first_post)\n",
    "credibility_rho1 = np.quantile(rho_first_post, [0.05, 0.5, 0.95])\n",
    "\n",
    "rho_second_post = second_post[:,-1]/second_post[:,0]\n",
    "mean_rho2 = np.mean(rho_second_post)\n",
    "std_rho2 = np.std(rho_second_post)\n",
    "credibility_rho2 = np.quantile(rho_second_post, [0.05, 0.5, 0.95])\n",
    "\n",
    "rho_third_post = third_post[:,-1]/third_post[:,0]\n",
    "mean_rho3 = np.mean(rho_third_post)\n",
    "std_rho3 = np.std(rho_third_post)\n",
    "credibility_rho3 = np.quantile(rho_third_post, [0.05, 0.5, 0.95])\n",
    "\n",
    "print(f\"Flat prior for p6/p1 posterior distribution:\\nMean: {round(mean_rho1, 3)}, std: {round(std_rho1, 3)}, cred_interval: {credibility_rho1}\")\n",
    "print(f\"\\nMore confident prior for p6/p1 posterior distribution:\\nMean: {round(mean_rho2, 3)}, std: {round(std_rho2, 3)}, cred_interval: {credibility_rho2}\")\n",
    "print(f\"\\nThe no guessing prior for p6/p1 posterior distribution:\\nMean: {round(mean_rho3, 3)}, std: {round(std_rho3, 3)}, cred_interval: {credibility_rho3}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### $\\alpha = \\frac16 \\sum_{j=1}^6 (p_j - \\frac16 )^2$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flat prior for alpha posterior distribution:\n",
      "Mean: 0.00703, std: 0.00376, cred_interval: [0.00210002 0.00641954 0.0140014 ]\n",
      "More confident prior for alpha posterior distribution:\n",
      "Mean: 0.00467, std: 0.00264, cred_interval: [0.001282   0.00420185 0.00962243]\n",
      "The no guessing prior for alpha posterior distribution:\n",
      "Mean: 0.00888, std: 0.00451, cred_interval: [0.0029088  0.00817108 0.01720447]\n"
     ]
    }
   ],
   "source": [
    "alpha_first_post = (1/6)*sum([(first_post[:,j] - (1/6))**2 for j in range(6)])\n",
    "mean_alpha1 = np.mean(alpha_first_post)\n",
    "std_alpha1 = np.std(alpha_first_post)\n",
    "credibility_alpha1 = np.quantile(alpha_first_post, [0.05, 0.5, 0.95])\n",
    "\n",
    "alpha_second_post = (1/6)*sum([(second_post[:,j] - (1/6))**2 for j in range(6)])\n",
    "mean_alpha2 = np.mean(alpha_second_post)\n",
    "std_alpha2 = np.std(alpha_second_post)\n",
    "credibility_alpha2 = np.quantile(alpha_second_post, [0.05, 0.5, 0.95])\n",
    "\n",
    "alpha_third_post = (1/6)*sum([(third_post[:,j] - (1/6))**2 for j in range(6)])\n",
    "mean_alpha3 = np.mean(alpha_third_post)\n",
    "std_alpha3 = np.std(alpha_third_post)\n",
    "credibility_alpha3 = np.quantile(alpha_third_post, [0.05, 0.5, 0.95])\n",
    "\n",
    "print(f\"Flat prior for alpha posterior distribution:\\nMean: {round(mean_alpha1,5)}, std: {round(std_alpha1,5)}, cred_interval: {credibility_alpha1}\")\n",
    "print(f\"More confident prior for alpha posterior distribution:\\nMean: {round(mean_alpha2,5)}, std: {round(std_alpha2,5)}, cred_interval: {credibility_alpha2}\")\n",
    "print(f\"The no guessing prior for alpha posterior distribution:\\nMean: {round(mean_alpha3,5)}, std: {round(std_alpha3,5)}, cred_interval: {credibility_alpha3}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### $\\beta = \\frac16 \\sum_{j=1}^6 |p_j - \\frac16 |$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flat prior for beta posterior distribution:\n",
      "Mean: 0.068, std: 0.019, cred_interval: [0.03777143 0.06779169 0.10049058]\n",
      "More confident prior for beta posterior distribution:\n",
      "Mean: 0.055, std: 0.016, cred_interval: [0.0294369  0.05450258 0.08364086]\n",
      "The no guessing prior for beta posterior distribution:\n",
      "Mean: 0.077, std: 0.02, cred_interval: [0.04429618 0.07665195 0.11144111]\n"
     ]
    }
   ],
   "source": [
    "beta_first_post = (1/6)*sum([np.abs(first_post[:,j] - (1/6)) for j in range(6)])\n",
    "mean_beta1 = np.mean(beta_first_post)\n",
    "std_beta1 = np.std(beta_first_post)\n",
    "credibility_beta1 = np.quantile(beta_first_post, [0.05, 0.5, 0.95])\n",
    "\n",
    "beta_second_post = (1/6)*sum([np.abs(second_post[:,j] - (1/6)) for j in range(6)])\n",
    "mean_beta2 = np.mean(beta_second_post)\n",
    "std_beta2 = np.std(beta_second_post)\n",
    "credibility_beta2 = np.quantile(beta_second_post, [0.05, 0.5, 0.95])\n",
    "\n",
    "beta_third_post = (1/6)*sum([np.abs(third_post[:,j] - (1/6)) for j in range(6)])\n",
    "mean_beta3 = np.mean(beta_third_post)\n",
    "std_beta3 = np.std(beta_third_post)\n",
    "credibility_beta3 = np.quantile(beta_third_post, [0.05, 0.5, 0.95])\n",
    "\n",
    "\n",
    "print(f\"Flat prior for beta posterior distribution:\\nMean: {round(mean_beta1,3)}, std: {round(std_beta1,3)}, cred_interval: {credibility_beta1}\")\n",
    "print(f\"More confident prior for beta posterior distribution:\\nMean: {round(mean_beta2,3)}, std: {round(std_beta2,3)}, cred_interval: {credibility_beta2}\")\n",
    "print(f\"The no guessing prior for beta posterior distribution:\\nMean: {round(mean_beta3,3)}, std: {round(std_beta3,3)}, cred_interval: {credibility_beta3}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### $\\gamma = \\frac{(p_4p_5p_6)^{\\frac13}}{(p_1p_2p_3)^{\\frac13}}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flat prior for gamma posterior distribution:\n",
      "Mean: 2.082, std: 0.843, cred_interval: [1.0564002  1.92093262 3.66260749]\n",
      "More confident prior for gamma posterior distribution:\n",
      "Mean: 1.667, std: 0.537, cred_interval: [0.96058515 1.58355606 2.66074806]\n",
      "The no guessing prior for gamma posterior distribution:\n",
      "Mean: 2.51, std: 1.217, cred_interval: [1.14510089 2.24510455 4.75458737]\n"
     ]
    }
   ],
   "source": [
    "gamma_first_post = (first_post[:,3]*first_post[:,4]*first_post[:,5])**(1/3)/(first_post[:,0]*first_post[:,1]*first_post[:,2])**(1/3)\n",
    "mean_gamma1 = np.mean(gamma_first_post)\n",
    "std_gamma1 = np.std(gamma_first_post)\n",
    "credibility_gamma1 = np.quantile(gamma_first_post, [0.05, 0.5, 0.95])\n",
    "\n",
    "gamma_second_post = (second_post[:,3]*second_post[:,4]*second_post[:,5])**(1/3)/(second_post[:,0]*second_post[:,1]*second_post[:,2])**(1/3)\n",
    "mean_gamma2 = np.mean(gamma_second_post)\n",
    "std_gamma2 = np.std(gamma_second_post)\n",
    "credibility_gamma2 = np.quantile(gamma_second_post, [0.05, 0.5, 0.95])\n",
    "\n",
    "# here is an other way to do the calcualtion, using log\n",
    "gamma_third_post = np.exp(1/3*(np.log(third_post[:,3]) + np.log(third_post[:,4]) + np.log(third_post[:,5]) - np.log(third_post[:,0]) - np.log(third_post[:,1]) - np.log(third_post[:,2])))\n",
    "mean_gamma3 = np.mean(gamma_third_post)\n",
    "std_gamma3 = np.std(gamma_third_post)\n",
    "credibility_gamma3 = np.quantile(gamma_third_post, [0.05, 0.5, 0.95])\n",
    "\n",
    "\n",
    "print(f\"Flat prior for gamma posterior distribution:\\nMean: {round(mean_gamma1,3)}, std: {round(std_gamma1,3)}, cred_interval: {credibility_gamma1}\")\n",
    "print(f\"More confident prior for gamma posterior distribution:\\nMean: {round(mean_gamma2,3)}, std: {round(std_gamma2,3)}, cred_interval: {credibility_gamma2}\")\n",
    "print(f\"The no guessing prior for gamma posterior distribution:\\nMean: {round(mean_gamma3,3)}, std: {round(std_gamma3,3)}, cred_interval: {credibility_gamma3}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (b)\n",
    "\n",
    "We have 6 observations, $y_1, ..., y_6$. We want to make a mixture prior to make it possbile that $\\rho =1, \\alpha=0, \\beta=0, \\gamma=1$ (see formulas below). Therefore we need a mixture prior with a flat Dirichlet and a confident Dirichlet (a confident in that sense that all throws have equal probability).\n",
    "\n",
    "We have multinomial as our likelihood function:\n",
    "\n",
    "#### $$(y_1, ..., y_6)|(\\theta_1, ..., \\theta_6) \\sim \\frac{n}{y_1! \\cdot ... \\cdot y_6!} \\theta_1^{y_1} \\cdot ... \\cdot \\theta_6^{y_6}$$\n",
    "\n",
    "Our prior is a mixture between a flat Dirichlet (1 on all points) and a Diriclet that makes it possible for our actual prob to be $\\frac16$:\n",
    "\n",
    "#### $$\\theta_1, ..., \\theta_6 \\sim \\frac12 Dir(1, ..., 1) + \\frac12 Dir(1000, ..., 1000)$$\n",
    "\n",
    "From this, our posterior will look like this:\n",
    "\n",
    "#### $$(\\theta_1, ..., \\theta_6)|(y_1, ..., y_6) \\sim w_1 Dir(1 y_1, ..., 1 y_6) + w_2 Dir(1000 y_1, ..., 1000 y_6)$$\n",
    "\n",
    "__NOTE:__ By \"+\", it is not meant that we add them togheter. A more \"pedagogical\" way of writing this is:\n",
    "\n",
    "\\begin{align*}\n",
    "(\\theta_1, ..., \\theta_6)|(y_1, ..., y_6) \\sim \n",
    "\\begin{cases} \n",
    "    Dir(1 y_1, \\cdots , 1 y_6) \\qquad \\text{, with }prob(w_1) \\\\\n",
    "    Dir(1000 y_1, ..., 1000 y_6) \\qquad \\text{, with }prob(w_2)\n",
    "  \\end{cases}\n",
    "\\end{align*}\n",
    "\n",
    "Where $w_i$ is:\n",
    "\n",
    "#### $$w_i = \\frac{\\frac12 f_i}{\\frac12 f_1 + \\frac12 f_2} \\quad i=1,2$$\n",
    "\n",
    "Note that $\\sum w_i = 1$. $f_i$ is the marginal of y for i=1,2:\n",
    "\n",
    "#### $$f_i = \\frac{\\Gamma(\\sum_{i=1}^6 a_i) \\Gamma(n+1)}{\\Gamma(n+\\sum_{i=1}^6 a_i)} \\prod_{i=1}^6 \\frac{\\Gamma(y_i + a_i)}{\\Gamma(a_i) \\Gamma(y_i + 1)} = \\frac{n B(\\sum_{i=1}^6 a_i , n)}{\\prod_{i=1}^6 y_i B(a_i, y_i)}$$\n",
    "\n",
    "Here, $B$ is the beta function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "from scipy.special import loggamma as lg\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.special import beta as bt\n",
    "\n",
    "large_number = 10**10  # take a lagre number to make it possible of 1/6\n",
    "sim = 10**5\n",
    "\n",
    "y_observed = np.array([2,5,3,7,5,8]) \n",
    "f1_prior = np.array([1,1,1,1,1,1])  # flat prior\n",
    "f2_prior = np.array([large_number for i in range(6)]) # prior that is very confident of 1/6\n",
    "\n",
    "n = sum(y_observed)\n",
    "\n",
    "f1 = (n*bt(sum(f1_prior), n))/np.prod(y_observed * bt(f1_prior, y_observed))\n",
    "f2 = (n*bt(sum(f2_prior), n))/np.prod(y_observed * bt(f2_prior, y_observed))\n",
    "\n",
    "\n",
    "# f1 and f2 can also be calculated as\n",
    "f1_1 = lg(sum(f1_prior))+lg(n+1) - lg(n+sum(f1_prior)) + np.sum(lg(y_observed+f1_prior) - lg(f1_prior)-lg(y_observed+1))\n",
    "f1_1 = np.exp(f1_1)\n",
    "f2_1 = lg(sum(f2_prior))+lg(n+1) - lg(n+sum(f2_prior)) + np.sum(lg(y_observed+f2_prior) - lg(f2_prior)-lg(y_observed+1))\n",
    "f2_1 = np.exp(f2_1)\n",
    "\n",
    "w1 = (1/2)*f1/((1/2)*f1+(1/2)*f2)\n",
    "w2 = (1/2)*f2/((1/2)*f1+(1/2)*f2)\n",
    "\n",
    "dist1 = stats.dirichlet.rvs(f1_prior+y_observed, size=sim)\n",
    "dist2 = stats.dirichlet.rvs(f2_prior+y_observed, size=sim)\n",
    "\n",
    "post = dist1*0\n",
    "\n",
    "uniform = stats.uniform.rvs(size=sim)\n",
    "\n",
    "for index, row in enumerate(post):\n",
    "    ok = 1*(uniform[index]<w2)\n",
    "    post[index] = ok*dist2[index] + (1-ok)*dist1[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.08269769276639732, 0.9173023072336027, 1.0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# note that w1 + w2 should be equal to 1\n",
    "w1, w2, w1+w2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Probability for $p = p_0 = (\\frac16, \\frac16, \\frac16, \\frac16, \\frac16, \\frac16)$?\n",
    "\n",
    "#### $\\rho = \\frac{p_6}{p_1}$:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fp6/p1 posterior distribution:\n",
      "Mean: 1.2959, std: 1.7119, cred_interval: [0.99997701 1.00000163 2.74972126]\n"
     ]
    }
   ],
   "source": [
    "rho_post = post[:,5]/post[:,0]\n",
    "mean_rho1 = np.mean(rho_post)\n",
    "std_rho1 = np.std(rho_post)\n",
    "credibility_rho1 = np.quantile(rho_post, [0.05, 0.5, 0.95])\n",
    "\n",
    "print(f\"Fp6/p1 posterior distribution:\\nMean: {round(mean_rho1, 4)}, std: {round(std_rho1, 4)}, cred_interval: {credibility_rho1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### $\\alpha = \\frac16 \\sum_{j=1}^6 (p_j - \\frac16 )^2$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha posterior distribution:\n",
      "Mean: 0.00059, std: 0.00222, cred_interval: [5.55701704e-13 2.16919338e-12 5.54222544e-03]\n"
     ]
    }
   ],
   "source": [
    "alpha_post = (1/6)*sum([(post[:,j] - (1/6))**2 for j in range(6)])\n",
    "mean_alpha = np.mean(alpha_post)\n",
    "std_alpha = np.std(alpha_post)\n",
    "credibility_alpha = np.quantile(alpha_post, [0.05, 0.5, 0.95])\n",
    "\n",
    "print(f\"Alpha posterior distribution:\\nMean: {round(mean_alpha,5)}, std: {round(std_alpha,5)}, cred_interval: {credibility_alpha}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### $\\beta = \\frac16 \\sum_{j=1}^6 |p_j - \\frac16 |$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beta posterior distribution:\n",
      "Mean: 0.00569, std: 0.01965, cred_interval: [6.15679635e-07 1.22985268e-06 6.23846378e-02]\n"
     ]
    }
   ],
   "source": [
    "beta_post = (1/6)*sum([np.abs(post[:,j] - (1/6)) for j in range(6)])\n",
    "mean_beta = np.mean(beta_post)\n",
    "std_beta = np.std(beta_post)\n",
    "credibility_beta = np.quantile(beta_post, [0.05, 0.5, 0.95])\n",
    "\n",
    "print(f\"Beta posterior distribution:\\nMean: {round(mean_beta,5)}, std: {round(std_beta,5)}, cred_interval: {credibility_beta}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### $\\gamma = \\frac{(p_4p_5p_6)^{\\frac13}}{(p_1p_2p_3)^{\\frac13}}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gamma posterior distribution:\n",
      "Mean: 1.09039, std: 0.38846, cred_interval: [0.99998675 1.00000092 1.74281191]\n"
     ]
    }
   ],
   "source": [
    "gamma_post = ((post[:,3]*post[:,4]*post[:,5])**(1/3))/((post[:,0]*post[:,1]*post[:,2])**(1/3))\n",
    "\n",
    "mean_gamma = np.mean(gamma_post)\n",
    "std_gamma = np.std(gamma_post)\n",
    "credibility_gamma = np.quantile(gamma_post, [0.05, 0.5, 0.95])\n",
    "\n",
    "print(f\"Gamma posterior distribution:\\nMean: {round(mean_gamma,5)}, std: {round(std_gamma,5)}, cred_interval: {credibility_gamma}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
