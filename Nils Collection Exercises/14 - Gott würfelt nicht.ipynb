{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gott w√ºrfelt nicht\n",
    "\n",
    "_but I do so, on demand. I throw a certain moderately strange-looking die 30 times and have counts (2, 5, 3, 7, 5, 8) of outcomes 1, 2, 3, 4, 5, 6._\n",
    "\n",
    "## (a) \n",
    "\n",
    "_Use either of the priors_\n",
    "* 'flat', Dir(1,1,1,1,1,1)\n",
    "* 'symmetric but more confident', Dir(3,3,3,3,3,3)\n",
    "* 'unwilling to guess', Dir(0.1, 0.1, 0.1, 0.1, 0.1, 0.1)\n",
    "\n",
    "_for  the probabilities (p1, . . . , p6) to assess the posterior distribution of each of the following quantities:_\n",
    "\n",
    "* $\\rho = p_6/p_1$ \n",
    "* $\\alpha = \\frac16 \\sum_{j=1}^6 (p_j - \\frac16 )^2$\n",
    "* $\\beta = \\frac16 \\sum_{j=1}^6 |p_j - \\frac16 |$\n",
    "* $\\gamma = \\frac{(p_4p_5p_6)^{\\frac13}}{(p_1p_2p_3)^{\\frac13}}$\n",
    "\n",
    "So, our prior is a Dirichlet, but for the model/likelihood I will use the Multinomial distirbution, which is an \"extensions\" of the binomial. Also note that the Dirichlet is a type of \"extension\" of the beta distribution. Thus, this will almost be the same as a Beta & Binomial problem (Beta prior, Binomial likelihood):\n",
    "\n",
    "Prior:\n",
    "\n",
    "$$\\theta_1, ..., \\theta_6 \\sim Dir(a_1, ..., a_6)$$\n",
    "\n",
    "Likelihood:\n",
    "\n",
    "$$(y_1, ..., y_6)|(\\theta_1, ..., \\theta_6) \\sim Multinomial(n, \\theta_1, ..., \\theta_6)$$\n",
    "\n",
    "Posterior: \n",
    "\n",
    "$$(\\theta_1, ..., \\theta_6)|(y_1, ..., y_6) \\sim Dir(a_1+y_1, ..., a_6+y_6)$$\n",
    "\n",
    "\n",
    "Now that we have established the posterior model, we can solve the problem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "import numpy as np\n",
    "y_vals = np.array([2,5,3,7,5,8])\n",
    "flat_prior = np.array([1,1,1,1,1,1])\n",
    "more_conf_prior = np.array([3,3,3,3,3,3])\n",
    "no_guessing_prior = np.array([0.1,0.1,0.1,0.1,0.1,0.1])\n",
    "\n",
    "first_post = stats.dirichlet.rvs(flat_prior+y_vals, size=10**5)\n",
    "second_post = stats.dirichlet.rvs(more_conf_prior+y_vals, size=10**5)\n",
    "third_post = stats.dirichlet.rvs(no_guessing_prior+y_vals, size=10**5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our different posterior distributions with each of their different prior distributions, we can go on to asses other types of posterior distributions.\n",
    "\n",
    "#### Assess different posterior distributions, with mean, std and credibility interval\n",
    "\n",
    "#### $\\rho = \\frac{p_6}{p_1}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flat prior for p6/p1 posterior distribution:\n",
      "Mean: 4.505, std: 4.591, cred_interval: [ 1.12230793  3.25077806 11.82415953]\n",
      "\n",
      "More confident prior for p6/p1 posterior distribution:\n",
      "Mean: 2.748, std: 1.848, cred_interval: [0.95505602 2.28397805 6.04021986]\n",
      "\n",
      "The no guessing prior for p6/p1 posterior distribution:\n",
      "Mean: 7.338, std: 13.621, cred_interval: [ 1.29693539  4.36749928 21.38520482]\n"
     ]
    }
   ],
   "source": [
    "rho_first_post = first_post[:,-1]/first_post[:,0]\n",
    "mean_rho1 = np.mean(rho_first_post)\n",
    "std_rho1 = np.std(rho_first_post)\n",
    "credibility_rho1 = np.quantile(rho_first_post, [0.05, 0.5, 0.95])\n",
    "\n",
    "rho_second_post = second_post[:,-1]/second_post[:,0]\n",
    "mean_rho2 = np.mean(rho_second_post)\n",
    "std_rho2 = np.std(rho_second_post)\n",
    "credibility_rho2 = np.quantile(rho_second_post, [0.05, 0.5, 0.95])\n",
    "\n",
    "rho_third_post = third_post[:,-1]/third_post[:,0]\n",
    "mean_rho3 = np.mean(rho_third_post)\n",
    "std_rho3 = np.std(rho_third_post)\n",
    "credibility_rho3 = np.quantile(rho_third_post, [0.05, 0.5, 0.95])\n",
    "\n",
    "print(f\"Flat prior for p6/p1 posterior distribution:\\nMean: {round(mean_rho1, 3)}, std: {round(std_rho1, 3)}, cred_interval: {credibility_rho1}\")\n",
    "print(f\"\\nMore confident prior for p6/p1 posterior distribution:\\nMean: {round(mean_rho2, 3)}, std: {round(std_rho2, 3)}, cred_interval: {credibility_rho2}\")\n",
    "print(f\"\\nThe no guessing prior for p6/p1 posterior distribution:\\nMean: {round(mean_rho3, 3)}, std: {round(std_rho3, 3)}, cred_interval: {credibility_rho3}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### $\\alpha = \\frac16 \\sum_{j=1}^6 (p_j - \\frac16 )^2$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flat prior for alpha posterior distribution:\n",
      "Mean: 0.00703, std: 0.00376, cred_interval: [0.00210002 0.00641954 0.0140014 ]\n",
      "More confident prior for alpha posterior distribution:\n",
      "Mean: 0.00467, std: 0.00264, cred_interval: [0.001282   0.00420185 0.00962243]\n",
      "The no guessing prior for alpha posterior distribution:\n",
      "Mean: 0.00888, std: 0.00451, cred_interval: [0.0029088  0.00817108 0.01720447]\n"
     ]
    }
   ],
   "source": [
    "alpha_first_post = (1/6)*sum([(first_post[:,j] - (1/6))**2 for j in range(6)])\n",
    "mean_alpha1 = np.mean(alpha_first_post)\n",
    "std_alpha1 = np.std(alpha_first_post)\n",
    "credibility_alpha1 = np.quantile(alpha_first_post, [0.05, 0.5, 0.95])\n",
    "\n",
    "alpha_second_post = (1/6)*sum([(second_post[:,j] - (1/6))**2 for j in range(6)])\n",
    "mean_alpha2 = np.mean(alpha_second_post)\n",
    "std_alpha2 = np.std(alpha_second_post)\n",
    "credibility_alpha2 = np.quantile(alpha_second_post, [0.05, 0.5, 0.95])\n",
    "\n",
    "alpha_third_post = (1/6)*sum([(third_post[:,j] - (1/6))**2 for j in range(6)])\n",
    "mean_alpha3 = np.mean(alpha_third_post)\n",
    "std_alpha3 = np.std(alpha_third_post)\n",
    "credibility_alpha3 = np.quantile(alpha_third_post, [0.05, 0.5, 0.95])\n",
    "\n",
    "print(f\"Flat prior for alpha posterior distribution:\\nMean: {round(mean_alpha1,5)}, std: {round(std_alpha1,5)}, cred_interval: {credibility_alpha1}\")\n",
    "print(f\"More confident prior for alpha posterior distribution:\\nMean: {round(mean_alpha2,5)}, std: {round(std_alpha2,5)}, cred_interval: {credibility_alpha2}\")\n",
    "print(f\"The no guessing prior for alpha posterior distribution:\\nMean: {round(mean_alpha3,5)}, std: {round(std_alpha3,5)}, cred_interval: {credibility_alpha3}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### $\\beta = \\frac16 \\sum_{j=1}^6 |p_j - \\frac16 |$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flat prior for beta posterior distribution:\n",
      "Mean: 0.068, std: 0.019, cred_interval: [0.03777143 0.06779169 0.10049058]\n",
      "More confident prior for beta posterior distribution:\n",
      "Mean: 0.055, std: 0.016, cred_interval: [0.0294369  0.05450258 0.08364086]\n",
      "The no guessing prior for beta posterior distribution:\n",
      "Mean: 0.077, std: 0.02, cred_interval: [0.04429618 0.07665195 0.11144111]\n"
     ]
    }
   ],
   "source": [
    "beta_first_post = (1/6)*sum([np.abs(first_post[:,j] - (1/6)) for j in range(6)])\n",
    "mean_beta1 = np.mean(beta_first_post)\n",
    "std_beta1 = np.std(beta_first_post)\n",
    "credibility_beta1 = np.quantile(beta_first_post, [0.05, 0.5, 0.95])\n",
    "\n",
    "beta_second_post = (1/6)*sum([np.abs(second_post[:,j] - (1/6)) for j in range(6)])\n",
    "mean_beta2 = np.mean(beta_second_post)\n",
    "std_beta2 = np.std(beta_second_post)\n",
    "credibility_beta2 = np.quantile(beta_second_post, [0.05, 0.5, 0.95])\n",
    "\n",
    "beta_third_post = (1/6)*sum([np.abs(third_post[:,j] - (1/6)) for j in range(6)])\n",
    "mean_beta3 = np.mean(beta_third_post)\n",
    "std_beta3 = np.std(beta_third_post)\n",
    "credibility_beta3 = np.quantile(beta_third_post, [0.05, 0.5, 0.95])\n",
    "\n",
    "\n",
    "print(f\"Flat prior for beta posterior distribution:\\nMean: {round(mean_beta1,3)}, std: {round(std_beta1,3)}, cred_interval: {credibility_beta1}\")\n",
    "print(f\"More confident prior for beta posterior distribution:\\nMean: {round(mean_beta2,3)}, std: {round(std_beta2,3)}, cred_interval: {credibility_beta2}\")\n",
    "print(f\"The no guessing prior for beta posterior distribution:\\nMean: {round(mean_beta3,3)}, std: {round(std_beta3,3)}, cred_interval: {credibility_beta3}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### $\\gamma = \\frac{(p_4p_5p_6)^{\\frac13}}{(p_1p_2p_3)^{\\frac13}}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flat prior for gamma posterior distribution:\n",
      "Mean: 2.082, std: 0.843, cred_interval: [1.0564002  1.92093262 3.66260749]\n",
      "More confident prior for gamma posterior distribution:\n",
      "Mean: 1.667, std: 0.537, cred_interval: [0.96058515 1.58355606 2.66074806]\n",
      "The no guessing prior for gamma posterior distribution:\n",
      "Mean: 2.51, std: 1.217, cred_interval: [1.14510089 2.24510455 4.75458737]\n"
     ]
    }
   ],
   "source": [
    "gamma_first_post = (first_post[:,3]*first_post[:,4]*first_post[:,5])**(1/3)/(first_post[:,0]*first_post[:,1]*first_post[:,2])**(1/3)\n",
    "mean_gamma1 = np.mean(gamma_first_post)\n",
    "std_gamma1 = np.std(gamma_first_post)\n",
    "credibility_gamma1 = np.quantile(gamma_first_post, [0.05, 0.5, 0.95])\n",
    "\n",
    "gamma_second_post = (second_post[:,3]*second_post[:,4]*second_post[:,5])**(1/3)/(second_post[:,0]*second_post[:,1]*second_post[:,2])**(1/3)\n",
    "mean_gamma2 = np.mean(gamma_second_post)\n",
    "std_gamma2 = np.std(gamma_second_post)\n",
    "credibility_gamma2 = np.quantile(gamma_second_post, [0.05, 0.5, 0.95])\n",
    "\n",
    "# here is an other way to do the calcualtion, using log\n",
    "gamma_third_post = np.exp(1/3*(np.log(third_post[:,3]) + np.log(third_post[:,4]) + np.log(third_post[:,5]) - np.log(third_post[:,0]) - np.log(third_post[:,1]) - np.log(third_post[:,2])))\n",
    "mean_gamma3 = np.mean(gamma_third_post)\n",
    "std_gamma3 = np.std(gamma_third_post)\n",
    "credibility_gamma3 = np.quantile(gamma_third_post, [0.05, 0.5, 0.95])\n",
    "\n",
    "\n",
    "print(f\"Flat prior for gamma posterior distribution:\\nMean: {round(mean_gamma1,3)}, std: {round(std_gamma1,3)}, cred_interval: {credibility_gamma1}\")\n",
    "print(f\"More confident prior for gamma posterior distribution:\\nMean: {round(mean_gamma2,3)}, std: {round(std_gamma2,3)}, cred_interval: {credibility_gamma2}\")\n",
    "print(f\"The no guessing prior for gamma posterior distribution:\\nMean: {round(mean_gamma3,3)}, std: {round(std_gamma3,3)}, cred_interval: {credibility_gamma3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
